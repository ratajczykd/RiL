{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "178acdc5",
   "metadata": {},
   "source": [
    "# Using ChatGPT for Automatic Comment Annotation\n",
    "\n",
    "In this part we will learn how to use the OpenAI API (ChatGPT) to automatically annotate text.\n",
    "We start with a single YouTube/Reddit comment, ask the model to return a sentiment label and score, and then extend the same idea to many comments in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d235fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade openai\n",
    "# !pip install openai llmx typing_extensions\n",
    "# !pip install --upgrade typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c4d660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c17bcbb4",
   "metadata": {},
   "source": [
    "## How to Create an OpenAI API Key\n",
    "\n",
    "1. Go to the OpenAI dashboard:\n",
    "https://platform.openai.com\n",
    "2. Sign in with your OpenAI account.\n",
    "3. Create a project and go to \"Settings\"\n",
    "4. In the left sidebar, click \"API Keys\".\n",
    "5. Click \"Create new secret key\".\n",
    "6. Copy, use it, and save it securely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ee0412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import of necessary packages\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2637faf",
   "metadata": {},
   "source": [
    "## Single-Comment Sentiment Annotation with ChatGPT\n",
    "\n",
    "In this section we:\n",
    "\n",
    "- connect to the OpenAI API using our API key,\n",
    "\n",
    "- define a system prompt describing how the model should behave, \n",
    "\n",
    "- send one comment and check the output.\n",
    "\n",
    "This is just a sanity check: we want to see whether the model understands the task and whether the returned JSON has the expected structure before we use it on a larger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db41d5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b68249",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "MODEL = \"gpt-5-mini\"\n",
    "\n",
    "system_prompt = \"\"\"You are an annotator.\n",
    "Return JSON with:\n",
    "- sentiment_label: one of [\"positive\",\"neutral\",\"negative\"]\n",
    "- sentiment_score: between -1 and 1 (negative→-1, neutral→0, positive→1)\n",
    "- rationale: short reason\n",
    "\"\"\"\n",
    "\n",
    "comment = \"I love this robot, it's so helpful!\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"Comment: {comment}\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144159ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b053d06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7b83a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b378328",
   "metadata": {},
   "source": [
    "# For multiple comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66899350",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=API_KEY)\n",
    "MODEL = \"gpt-5-mini\"\n",
    "\n",
    "def annotate_comment(text):\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Rate the sentiment of the following comment in English:\n",
    "    '{text[:500]}'\n",
    "\n",
    "    Respond with a single number between -1 and 1:\n",
    "    -1 = very negative\n",
    "     0 = neutral\n",
    "    +1 = very positive\n",
    "\n",
    "    Output ONLY the number, nothing else.\n",
    "    \"\"\"\n",
    "    response = client.responses.create(\n",
    "        model=MODEL,\n",
    "        input=prompt\n",
    "    )\n",
    "    # Extract text and convert to float\n",
    "    value_str = response.output_text.strip()\n",
    "    try:\n",
    "        return float(value_str)\n",
    "    except ValueError:\n",
    "        print(f\"Unexpected output: {value_str}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c71d27",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "Annotating Sentiment for One Robot and Comparing with VADER.\n",
    "\n",
    "In this exercise, you will compare two sentiment-analysis methods: annotated by ChatGPT and VADER (from last week).\n",
    "Goal is to see how similar these two methods are when evaluating the same comments.\n",
    "\n",
    "1. Load the comment dataset for one robot.\n",
    "2. Apply annotate_comment() function that sends each comment to ChatGPT and returns only one numeric sentiment value.\n",
    "3. Compare ChatGPT scores with the VADER scores from last week:\n",
    "    - compute a correlation coefficient (Pearson or Spearman),\n",
    "    - make a simple scatterplot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9688f497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('') # put name of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b48aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aa432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple comments annotation:\n",
    "#df[\"gpt_sent\"] = df[\"comment\"].apply(annotate_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeb6b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c32338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation:\n",
    "#print(df[\"gpt_sent\"].corr(df[\"vader_sent\"], method=\"pearson\"))\n",
    "#print(df[\"gpt_sent\"].corr(df[\"vader_sent\"], method=\"spearman\"))\n",
    "\n",
    "\n",
    "# scatterplot: \n",
    "#plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c79d309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcfd6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60aae2c4",
   "metadata": {},
   "source": [
    "# Designing Your Own Prompt for Tagging Vector Robot Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7016a728",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb03922",
   "metadata": {},
   "source": [
    "Create a clear, effective prompt for ChatGPT that annotates Reddit comments about the Vector robot (from 2 weeks ago). \n",
    "First, experiment with ChatGPT manually using an example comment to understand how it responds. \n",
    "Once you are satisfied with the output, use your prompt to automatically annotate 100 comments in Python.\n",
    "\n",
    "You can refer to the scientific article with the description of the annotation method:\n",
    "https://reference-global.com/2/v2/download/pdf/10.14313/jamris/2-2022/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed072a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use comments used for counting Kappa:\n",
    "df = pd.read_csv('vector-annotation-all.csv')\n",
    "\n",
    "# We are going to use only subset of first 100 comments:\n",
    "df = df[:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a702d26",
   "metadata": {},
   "source": [
    "### Tag‐set used for the Reddit study\n",
    "1. SE description of emotional states\n",
    "2. WA joint activities\n",
    "3. AU the assignment of autonomy\n",
    "4. PR the assignment of preferences\n",
    "5. OTHER other manifestations of anthropo‑\n",
    "morphization\n",
    "6. NONE no anthropomorphization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147860f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=API_KEY)\n",
    "MODEL = \"gpt-5-mini\"\n",
    "\n",
    "\n",
    "def annotate_tags(text):\n",
    "\n",
    "    # Messages for the chat model:\n",
    "    # - system: general instructions how the chat should behave\n",
    "    # - user: the actual input (comment in this case)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "PUT YOUR PROMPT HERE\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Reddit comment:\\n\"\n",
    "                f\"\\\"\\\"\\\"{text}\\\"\\\"\\\"\\n\\n\"\n",
    "                \"Answer with exactly ONE tag: SE, WA, AU, PR, OTHER, or NONE.\"\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Call the chat completion API\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    # Get the model's answer (a string)\n",
    "    raw_output = response.choices[0].message.content.strip().upper()\n",
    "\n",
    "    return raw_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c615a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = \"Vector gets sad when I leave and happy when I come back.\"\n",
    "\n",
    "label = annotate_tags(comment)\n",
    "print(\"Label:\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5349b73e",
   "metadata": {},
   "source": [
    "## Annotation of all 100 comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e77a6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"gpt_annotation\"] = df['COMMENT'].apply(annotate_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5b33de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output to file\n",
    "df.to_csv('gpt-annotated-vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589d4cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the output:\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685baffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7158065",
   "metadata": {},
   "source": [
    "### Cohen's kappa for comparison of mannually annotated and chat-GPT annotated comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da787c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotators = ['Annotator1', 'Annotator2', 'Annotator3']\n",
    "\n",
    "for ann in annotators:\n",
    "    kappa = cohen_kappa_score(df[ann], df['gpt_annotation'])\n",
    "    print(f\"Cohen's kappa ({ann} vs GPT): {kappa:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab98eea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
