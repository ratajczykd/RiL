{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39b9617",
   "metadata": {},
   "source": [
    "# Jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0e15c6",
   "metadata": {},
   "source": [
    "Useful keyboard shortcuts:\n",
    "- Shift + Enter – run the code\n",
    "- Esc + b – create a new cell\n",
    "- Esc + m – change the cell to a markdown (comment) cell\n",
    "- Ctrl + Shift + Minus – split the cell in half\n",
    "- Shift + Tab – show information about a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7297d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0180e469",
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82beee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e92f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971d0f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infinite loop in the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddaaad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d94bd95d",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eb235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f063995",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"name\": [\"Ada\", \"Ben\", \"Chao\", \"Dia\"],\n",
    "        \"age\": [29, 31, 27, 31],\n",
    "        \"score\": [88, 92, 79, 92]}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02461d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146cf866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Selecting data\n",
    "df[\"score\"]   # a Series (one column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6dcfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"name\",\"score\"]]        # a DataFrame (two columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d3929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering data\n",
    "df[df[\"score\"] > 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712a66e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save:\n",
    "df.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6239e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load:\n",
    "df2 = pd.read_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc4f4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06d38ee0",
   "metadata": {},
   "source": [
    "# Downloading Youtube comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0157b1c5",
   "metadata": {},
   "source": [
    "API key (YouTube Data API v3). \n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Go to Google Cloud Console \n",
    "2. Create project \n",
    "3. Enable APIs & Services \n",
    "4. Enable YouTube Data API v3 \n",
    "5. Credentials  \n",
    "6. Create API key.\n",
    "7. Paste the key into the code below.\n",
    "8. Keep it safe! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a6ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install pandas requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87707d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, requests, pandas as pd\n",
    "\n",
    "API_KEY = \"\"   # <-- put your YouTube Data API key here\n",
    "\n",
    "VIDEO_URL = \"https://www.youtube.com/watch?v=RiTfe-ckD_g\"  # example Ameca video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c124e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse as up\n",
    "video_id = up.parse_qs(up.urlparse(VIDEO_URL).query)[\"v\"][0]\n",
    "print(\"Video ID:\", video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19326103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html(s):\n",
    "    return re.sub(\"<.*?>\", \"\", s or \"\").replace(\"&amp;\",\"&\").strip()\n",
    "\n",
    "def yt_get(endpoint, params):\n",
    "    base = f\"https://www.googleapis.com/youtube/v3/{endpoint}\"\n",
    "    params = {**params, \"key\": API_KEY}\n",
    "    r = requests.get(base, params=params, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def fetch_comments(video_id, max_comments=200):\n",
    "    out = []\n",
    "    page = None\n",
    "    pulled = 0\n",
    "    while pulled < max_comments:\n",
    "        params = {\n",
    "            \"part\": \"snippet\",\n",
    "            \"videoId\": video_id,\n",
    "            \"maxResults\": min(100, max_comments - pulled),\n",
    "            \"textFormat\": \"html\"\n",
    "        }\n",
    "        if page:\n",
    "            params[\"pageToken\"] = page\n",
    "        data = yt_get(\"commentThreads\", params)\n",
    "        for item in data.get(\"items\", []):\n",
    "            top = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
    "            out.append({\n",
    "                \"commentId\": item[\"id\"],\n",
    "                \"date\": top[\"publishedAt\"],\n",
    "                \"author\": top.get(\"authorDisplayName\",\"\"),\n",
    "                \"text\": strip_html(top.get(\"textDisplay\",\"\")),\n",
    "                \"likeCount\": top.get(\"likeCount\", 0),\n",
    "            })\n",
    "            pulled += 1\n",
    "            if pulled >= max_comments:\n",
    "                break\n",
    "        page = data.get(\"nextPageToken\")\n",
    "        if not page:\n",
    "            break\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc69c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = fetch_comments(video_id, max_comments=200)\n",
    "df = pd.DataFrame(comments).drop_duplicates(subset=[\"commentId\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"Collected\", len(df), \"comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88539fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1881b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(full_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c8db1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70e7dfaf",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0988f26",
   "metadata": {},
   "source": [
    "Download and save the comments for the medium humanlike robot and the low humanlike robot as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d331894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f898db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2923f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "360453fe",
   "metadata": {},
   "source": [
    "# Sentiment analisys with Vader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fa91f0",
   "metadata": {},
   "source": [
    "VADER is a rule-based sentiment analysis tool that uses a lexicon of words and simple heuristics to determine the positive, negative, or neutral tone of text, especially effective for social media language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e371b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e707aac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f037f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I love this robot, it's amazing!\"\n",
    "scores = analyzer.polarity_scores(text)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eff3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfbbafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.polarity_scores(df['text'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af0cf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"vader_score\"] = df[\"text\"].apply(lambda t : an.polarity_scores(t)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6136e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5905e508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbb59bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vader_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3404b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['vader_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ade4b0",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ed3269",
   "metadata": {},
   "source": [
    "Analize sentiment for all comments from exercise 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594e9c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ac6b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ebd7e3d",
   "metadata": {},
   "source": [
    "### Comparing Robots\n",
    "\n",
    "When we have sentiment scores for multiple robots, we can statistically test whether the robots differ.\n",
    "\n",
    "Kruskal–Wallis is a non-parametric test that compares three or more groups.\n",
    "\n",
    "We use it to check:\n",
    "\n",
    "> Do comments about robots with different humanlikeness levels show different sentiment?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532cd0cc",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b92a6ae",
   "metadata": {},
   "source": [
    "Statistically compare the sentiment scores for the robots using the Kruskal–Wallis test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2565ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "# kruskal wallis\n",
    "# scipy.stats.kruskal(group1, group2, group3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaaa711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# post hocs\n",
    "#import scikit_posthocs as sp\n",
    "#sp.posthoc_dunn(df, val_col='score', group_col='group', p_adjust='bonferroni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfb58ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174b4f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b1a226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ea31dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c1719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Ameca_youtube_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c07fdd",
   "metadata": {},
   "source": [
    "## Example research questions\n",
    "\n",
    "Using these tools, we can study questions such as:\n",
    "\n",
    "- Does the **humanlikeness** of humanoid robots relate to emotional attitudes toward them?  \n",
    "- Do different **categories of robots** (social robots, pet robots, industrial robots, etc.) evoke different attitudes?  \n",
    "- Is the **gender or race** of robots related to emotional attitudes expressed in comments?\n",
    "\n",
    "For example, we can divide robots into categories based on **humanlikeness** (humanlike vs. non-humanlike), search for videos about these robots, collect the comments, and run sentiment analysis.  \n",
    "By comparing sentiment between these groups, we can answer questions like:\n",
    "\n",
    "> Do people react differently to **humanlike** robots than to **non-humanlike** robots?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957f4fa7",
   "metadata": {},
   "source": [
    "# Lexicon-based specific context analisys "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d7dd99",
   "metadata": {},
   "source": [
    "We can also measure the presence of specific words related to phenomenon we are interested in.\n",
    "\n",
    "Steps:\n",
    "1. Create list of words related to some phenomenon.\n",
    "2. Split each comment into lowercase words\n",
    "3. Count how many phenomenon-related words appear\n",
    "4. Compute index = (total number of related words / total words) * 1000\n",
    "\n",
    "This gives a simple index for each robot/category of robots\n",
    "\n",
    "For example: eeriness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504a77d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eerie = {'eerie','creepy','haunting','spookish','spooky','uncanny','unearthly','weird'}\n",
    "\n",
    "# https://www.merriam-webster.com/thesaurus/eerie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c420787",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187f29cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "toks = df['text'].fillna('').str.lower().str.findall(r'[a-z]+') \n",
    "# make all text lowercase, replace missing with empty, and split into words\n",
    "\n",
    "word_count = toks.str.len()\n",
    "\n",
    "total_eerie = 0\n",
    "for ws in toks:           \n",
    "    e_count = 0\n",
    "    for w in ws:\n",
    "        if w in eerie:\n",
    "            e_count += 1\n",
    "    total_eerie += e_count\n",
    "\n",
    "total_words = int(word_count.sum())\n",
    "eerie_per_1000 = (total_eerie / max(total_words, 1)) * 1000\n",
    "\n",
    "print(\"total_words:\", total_words)\n",
    "print(\"total_eerie_words:\", total_eerie)\n",
    "print(\"eerie_per_1000:\", eerie_per_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29646e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12593e25",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "\n",
    "Create Your Own Lexicon-Based Index\n",
    "\n",
    "Choose any psychological or thematic concept and create your own **word list** representing that concept. Then:\n",
    "\n",
    "1. Build a simple lexicon based on dictionary.\n",
    "2. Loop through all comments for one robot.\n",
    "3. Count how many words from your lexicon appear in the comments.\n",
    "4. Compute an index such as:\n",
    "   - occurances per 1000 words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8493a90c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
